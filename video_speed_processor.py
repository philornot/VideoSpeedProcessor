#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Video Speed Processor with GUI - FIXED VERSION
Automatycznie przetwarza nagrania wideo, przyspieszajƒÖc fragmenty ciszy
z prostym interfejsem graficznym.

NAPRAWIONE B≈ÅƒòDY:
- Poprawiona agregacja segment√≥w w WebRTC i Energy
- Dodane sprawdzanie poprawno≈õci segment√≥w
- Naprawione zarzƒÖdzanie pamiƒôciƒÖ (zamykanie klip√≥w)
- Poprawione EDL z prawid≈Çowym timecode
- Dodana walidacja danych wej≈õciowych
- Lepsze obs≈Çuga b≈Çƒôd√≥w
- Optymalizacja wydajno≈õci
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import os
import sys
import json
import logging
import threading
from pathlib import Path
from typing import List, Tuple, Optional
import queue
import tempfile
import shutil

# Importy zewnƒôtrzne
try:
    import moviepy.editor as mp
    import librosa
    import numpy as np
except ImportError as e:
    print(f"B≈ÇƒÖd: Brak wymaganych bibliotek. Zainstaluj: pip install moviepy librosa numpy")
    sys.exit(1)

# Opcjonalne importy
try:
    import webrtcvad

    WEBRTC_AVAILABLE = True
except ImportError:
    WEBRTC_AVAILABLE = False

try:
    import whisper

    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False


class LogHandler(logging.Handler):
    """Handler do przekierowania log√≥w do GUI."""

    def __init__(self, log_queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record):
        self.log_queue.put(self.format(record))


class VideoProcessor:
    """Klasa do przetwarzania wideo."""

    def __init__(self, progress_callback=None, log_callback=None):
        self.progress_callback = progress_callback
        self.log_callback = log_callback
        self.logger = self._setup_logging()
        self._temp_files = []  # Lista plik√≥w tymczasowych do wyczyszczenia

    def __del__(self):
        """Cleanup plik√≥w tymczasowych."""
        self._cleanup_temp_files()

    def _cleanup_temp_files(self):
        """Usuwa pliki tymczasowe."""
        for temp_file in self._temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                self.logger.warning(f"Nie mo≈ºna usunƒÖƒá pliku tymczasowego {temp_file}: {e}")
        self._temp_files.clear()

    def _setup_logging(self):
        """Konfiguracja logowania."""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)

        # Usu≈Ñ poprzednie handlery
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)

        # Dodaj handler do pliku
        try:
            file_handler = logging.FileHandler('video_speed_processor.log', encoding='utf-8')
            file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
            logger.addHandler(file_handler)
        except Exception as e:
            print(f"Nie mo≈ºna utworzyƒá pliku log√≥w: {e}")

        return logger

    def _update_progress(self, message: str, progress: float = None):
        """Aktualizuje progress i logi."""
        self.logger.info(message)
        if self.progress_callback:
            self.progress_callback(message, progress)

    def _validate_segments(self, segments: List[Tuple[float, float, bool]], audio_duration: float) -> List[
        Tuple[float, float, bool]]:
        """Waliduje i poprawia segmenty."""
        if not segments:
            return [(0.0, audio_duration, False)]

        validated = []
        for start, end, is_speech in segments:
            # Sprawd≈∫ poprawno≈õƒá czas√≥w
            start = max(0.0, start)
            end = min(audio_duration, end)

            if end <= start:
                continue  # Pomi≈Ñ nieprawid≈Çowe segmenty

            if end - start < 0.1:  # Minimum 0.1s
                continue

            validated.append((start, end, is_speech))

        # Sortuj wed≈Çug czasu rozpoczƒôcia
        validated.sort(key=lambda x: x[0])

        # Wype≈Çnij luki miƒôdzy segmentami
        filled = []
        current_time = 0.0

        for start, end, is_speech in validated:
            # Luka przed segmentem
            if start > current_time + 0.1:
                filled.append((current_time, start, False))  # Cisza w luce

            filled.append((start, end, is_speech))
            current_time = end

        # Pozosta≈Ça czƒô≈õƒá na ko≈Ñcu
        if current_time < audio_duration - 0.1:
            filled.append((current_time, audio_duration, False))

        return filled

    def detect_speech_segments(self, audio_path: str, method: str = 'webrtc',
                               min_silence_duration: float = 1.5) -> List[Tuple[float, float, bool]]:
        """Wykrywa segmenty mowy i ciszy."""
        self._update_progress(f"Wykrywanie segment√≥w mowy metodƒÖ: {method}")

        try:
            audio_duration = librosa.get_duration(filename=audio_path)
        except Exception as e:
            self.logger.error(f"Nie mo≈ºna odczytaƒá d≈Çugo≈õci audio: {e}")
            return []

        if audio_duration < 0.5:
            self.logger.warning("Plik audio jest zbyt kr√≥tki")
            return [(0.0, audio_duration, True)]  # Ca≈Çy plik jako mowa

        if method == 'whisper' and WHISPER_AVAILABLE:
            segments = self._detect_speech_whisper(audio_path, min_silence_duration)
        elif method == 'webrtc' and WEBRTC_AVAILABLE:
            segments = self._detect_speech_webrtc(audio_path, min_silence_duration)
        else:
            segments = self._detect_speech_energy(audio_path, min_silence_duration)

        # Waliduj segmenty
        validated_segments = self._validate_segments(segments, audio_duration)

        self._update_progress(f"Znaleziono {len(validated_segments)} segment√≥w")
        return validated_segments

    def _detect_speech_whisper(self, audio_path: str, min_silence_duration: float) -> List[Tuple[float, float, bool]]:
        """Detekcja mowy u≈ºywajƒÖc Whisper."""
        try:
            self._update_progress("≈Åadowanie modelu Whisper...")
            model = whisper.load_model("base")

            self._update_progress("Transkrypcja audio...")
            result = model.transcribe(audio_path, word_timestamps=True)

            segments = []
            audio_duration = librosa.get_duration(filename=audio_path)
            current_time = 0.0

            # Przetw√≥rz segmenty Whisper
            for segment in result.get('segments', []):
                start = max(0.0, segment.get('start', 0.0))
                end = min(audio_duration, segment.get('end', start + 1.0))

                if end <= start:
                    continue

                # Cisza przed segmentem
                if start > current_time + 0.5:
                    segments.append((current_time, start, False))

                # Segment mowy
                segments.append((start, end, True))
                current_time = end

            # Pozosta≈Ça cisza
            if current_time < audio_duration - 0.5:
                segments.append((current_time, audio_duration, False))

            return segments

        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd Whisper: {e}")
            return self._detect_speech_energy(audio_path, min_silence_duration)

    def _detect_speech_webrtc(self, audio_path: str, min_silence_duration: float) -> List[Tuple[float, float, bool]]:
        """Detekcja mowy u≈ºywajƒÖc WebRTC VAD - NAPRAWIONA."""
        try:
            self._update_progress("≈Åadowanie audio dla WebRTC...")
            y, sr = librosa.load(audio_path, sr=16000)

            if len(y) < 1600:  # Minimum 0.1s dla 16kHz
                return [(0.0, len(y) / sr, True)]

            vad = webrtcvad.Vad(2)  # ≈örednia czu≈Ço≈õƒá
            frame_duration = 0.02  # 20ms - stabilniejsze ni≈º 30ms
            frame_length = int(sr * frame_duration)

            speech_decisions = []

            # Przetwarzaj ramki
            for i in range(0, len(y) - frame_length, frame_length):
                frame = y[i:i + frame_length]
                frame_time = i / sr

                # Konwersja do int16
                frame_int16 = np.clip(frame * 32767, -32768, 32767).astype(np.int16)
                frame_bytes = frame_int16.tobytes()

                try:
                    is_speech = vad.is_speech(frame_bytes, sr)
                    speech_decisions.append((frame_time, is_speech))
                except Exception:
                    # W przypadku b≈Çƒôdu, zak≈Çadaj ciszƒô
                    speech_decisions.append((frame_time, False))

            if not speech_decisions:
                return [(0.0, len(y) / sr, False)]

            # NAPRAWIONA AGREGACJA: U≈ºyj sliding window
            window_size = max(1, int(0.5 / frame_duration))  # 0.5s okno
            smoothed_decisions = []

            for i, (frame_time, _) in enumerate(speech_decisions):
                # Sprawd≈∫ otoczenie
                start_idx = max(0, i - window_size // 2)
                end_idx = min(len(speech_decisions), i + window_size // 2 + 1)

                speech_votes = sum(1 for _, is_speech in speech_decisions[start_idx:end_idx] if is_speech)
                total_votes = end_idx - start_idx

                # Decyzja wiƒôkszo≈õciowa z progiem
                is_speech = speech_votes > total_votes * 0.3  # 30% pr√≥g
                smoothed_decisions.append((frame_time, is_speech))

            # Agreguj w segmenty
            segments = []
            if smoothed_decisions:
                current_start = 0.0
                current_is_speech = smoothed_decisions[0][1]

                for frame_time, is_speech in smoothed_decisions[1:]:
                    if is_speech != current_is_speech:
                        duration = frame_time - current_start
                        if duration >= 0.3:  # Minimum 0.3s segment
                            segments.append((current_start, frame_time, current_is_speech))
                            current_start = frame_time
                            current_is_speech = is_speech

                # Ostatni segment
                audio_duration = len(y) / sr
                if audio_duration - current_start >= 0.3:
                    segments.append((current_start, audio_duration, current_is_speech))

            # Filtruj kr√≥tkie segmenty ciszy
            return self._filter_short_silences(segments, min_silence_duration)

        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd WebRTC: {e}")
            return self._detect_speech_energy(audio_path, min_silence_duration)

    def _detect_speech_energy(self, audio_path: str, min_silence_duration: float) -> List[Tuple[float, float, bool]]:
        """Detekcja na podstawie energii audio - NAPRAWIONA."""
        try:
            self._update_progress("Analiza energii audio...")
            y, sr = librosa.load(audio_path)

            if len(y) < sr * 0.5:  # Minimum 0.5s
                return [(0.0, len(y) / sr, True)]

            # Parametry analizy
            frame_length = int(sr * 0.25)  # 250ms ramki
            hop_length = int(sr * 0.125)  # 125ms przeskok

            # Oblicz RMS i spectral centroid dla lepszej detekcji
            rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
            spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length)[0]

            # Normalizuj features
            rms_norm = (rms - np.min(rms)) / (np.max(rms) - np.min(rms) + 1e-8)
            centroid_norm = (spectral_centroid - np.min(spectral_centroid)) / (
                        np.max(spectral_centroid) - np.min(spectral_centroid) + 1e-8)

            # Kombinowany wska≈∫nik
            combined_energy = 0.7 * rms_norm + 0.3 * centroid_norm

            # Adaptacyjny pr√≥g
            threshold = np.percentile(combined_energy, 30)  # Ni≈ºszy pr√≥g dla lepszej detekcji

            times = librosa.frames_to_time(np.arange(len(combined_energy)), sr=sr, hop_length=hop_length)

            # Wyg≈Çad≈∫ decyzje
            window_size = max(1, int(1.0 / (hop_length / sr)))  # 1s okno
            smoothed_energy = np.convolve(combined_energy, np.ones(window_size) / window_size, mode='same')

            # Agreguj w segmenty
            segments = []
            current_start = 0.0
            current_is_speech = smoothed_energy[0] > threshold

            for i, (time, energy) in enumerate(zip(times[1:], smoothed_energy[1:]), 1):
                is_speech = energy > threshold

                if is_speech != current_is_speech:
                    duration = time - current_start
                    if duration >= 0.5:  # Minimum 0.5s segment
                        segments.append((current_start, time, current_is_speech))
                        current_start = time
                        current_is_speech = is_speech

            # Ostatni segment
            audio_duration = len(y) / sr
            if audio_duration - current_start >= 0.5:
                segments.append((current_start, audio_duration, current_is_speech))

            return self._filter_short_silences(segments, min_silence_duration)

        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd detekcji energii: {e}")
            return []

    def _filter_short_silences(self, segments: List[Tuple[float, float, bool]], min_silence_duration: float) -> List[
        Tuple[float, float, bool]]:
        """Filtruje kr√≥tkie segmenty ciszy, ≈ÇƒÖczƒÖc je z sƒÖsiednimi segmentami mowy."""
        if not segments:
            return segments

        filtered = []
        for start, end, is_speech in segments:
            duration = end - start

            if is_speech or duration >= min_silence_duration:
                filtered.append((start, end, is_speech))
            else:
                # Kr√≥tka cisza - zamie≈Ñ na mowƒô
                filtered.append((start, end, True))

        return filtered

    def create_speed_overlay(self, text: str, duration: float, video_size: Tuple[int, int]) -> Optional[mp.VideoClip]:
        """Tworzy overlay z tekstem prƒôdko≈õci - NAPRAWIONY."""
        try:
            # Sprawd≈∫ dostƒôpno≈õƒá ImageMagick
            test_clip = mp.TextClip("test", fontsize=10, color='white')
            test_clip.close()

            # Je≈õli test przeszed≈Ç, utw√≥rz prawdziwy overlay
            overlay = mp.TextClip(
                text,
                fontsize=max(24, min(video_size) // 20),  # Mniejszy tekst
                color='yellow',
                font='Arial-Bold' if sys.platform == 'win32' else 'DejaVu-Sans-Bold',
                stroke_color='black',
                stroke_width=2
            ).set_duration(duration)

            # Pozycja w prawym dolnym rogu z marginesem
            margin = max(20, min(video_size) // 40)
            overlay = overlay.set_position((
                video_size[0] - overlay.w - margin,
                video_size[1] - overlay.h - margin
            )).set_opacity(0.9)

            return overlay

        except Exception as e:
            self.logger.warning(f"Nie mo≈ºna utworzyƒá overlay tekstowego: {e}")
            return self._create_simple_overlay(text, duration, video_size)

    def _create_simple_overlay(self, text: str, duration: float, video_size: Tuple[int, int]) -> Optional[mp.VideoClip]:
        """Fallback overlay - kolorowy prostokƒÖt - NAPRAWIONY."""
        try:
            rect_size = max(30, min(video_size) // 25)

            def make_frame(t):
                frame = np.zeros((rect_size, rect_size, 3), dtype=np.uint8)

                # Kolor zale≈ºny od prƒôdko≈õci
                if 'x5' in text:
                    color = [255, 0, 0]  # Czerwony dla x5
                elif 'x4' in text:
                    color = [255, 128, 0]  # Pomara≈Ñczowy dla x4
                elif 'x3' in text:
                    color = [255, 255, 0]  # ≈ª√≥≈Çty dla x3
                else:
                    color = [0, 255, 0]  # Zielony dla innych

                frame[:, :] = color
                return frame

            overlay = mp.VideoClip(make_frame, duration=duration)

            # Pozycja w prawym dolnym rogu
            margin = max(20, min(video_size) // 40)
            overlay = overlay.set_position((
                video_size[0] - rect_size - margin,
                video_size[1] - rect_size - margin
            )).set_opacity(0.8)

            return overlay

        except Exception as e:
            self.logger.error(f"Nie mo≈ºna utworzyƒá prostego overlay: {e}")
            return None

    def process_video(self, input_path: str, output_folder: str, speed_multiplier: float = 3.0,
                      min_silence_duration: float = 1.5, detection_method: str = 'webrtc',
                      create_video: bool = True) -> Optional[dict]:
        """Przetwarza pojedynczy plik wideo - NAPRAWIONY."""
        self._update_progress(f"≈Åadowanie wideo: {os.path.basename(input_path)}")

        video = None
        processed_clips = []

        try:
            # Walidacja pliku wej≈õciowego
            if not os.path.exists(input_path):
                raise FileNotFoundError(f"Plik nie istnieje: {input_path}")

            file_size = os.path.getsize(input_path)
            if file_size < 1024:  # Mniej ni≈º 1KB
                raise ValueError(f"Plik jest zbyt ma≈Çy: {file_size} bajt√≥w")

            video = mp.VideoFileClip(input_path)

            if video.duration < 1.0:
                raise ValueError(f"Wideo jest zbyt kr√≥tkie: {video.duration}s")

            # Sprawd≈∫ czy video ma audio
            if video.audio is None:
                self.logger.warning("Wideo nie ma ≈õcie≈ºki audio - traktowanie jako cisza")
                return {
                    'input_file': input_path,
                    'input_name': Path(input_path).stem,
                    'timeline_data': [{'start': 0, 'end': video.duration, 'duration': video.duration, 'speed': 1.0,
                                       'type': 'no_audio'}],
                    'original_duration': video.duration,
                    'output_duration': video.duration,
                    'segments_count': 1
                }

            # Wyodrƒôbnij audio do pliku tymczasowego
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_audio:
                temp_audio_path = tmp_audio.name
                self._temp_files.append(temp_audio_path)

            self._update_progress("Wyodrƒôbnianie audio...")
            try:
                video.audio.write_audiofile(temp_audio_path, verbose=False, logger=None)
            except Exception as e:
                raise RuntimeError(f"Nie mo≈ºna wyodrƒôbniƒá audio: {e}")

            # Wykryj segmenty
            segments = self.detect_speech_segments(temp_audio_path, detection_method, min_silence_duration)

            if not segments:
                raise ValueError("Nie znaleziono ≈ºadnych segment√≥w")

            self._update_progress(f"Przetwarzanie {len(segments)} segment√≥w...")

            # Przetw√≥rz segmenty
            timeline_data = []
            total_output_duration = 0.0

            for i, (start, end, is_speech) in enumerate(segments):
                progress = (i / len(segments)) * 100
                self._update_progress(f"Segment {i + 1}/{len(segments)}", progress)

                # Walidacja segmentu
                start = max(0.0, start)
                end = min(video.duration, end)

                if end <= start:
                    continue

                duration = end - start

                try:
                    clip = video.subclip(start, end)

                    if is_speech:
                        # Normalne tempo dla mowy
                        timeline_data.append({
                            'start': start,
                            'end': end,
                            'duration': duration,
                            'speed': 1.0,
                            'type': 'speech'
                        })
                        total_output_duration += duration
                    else:
                        # Przyspiesz ciszƒô
                        if duration >= min_silence_duration:
                            # Sprawd≈∫ czy speed_multiplier jest rozsƒÖdny
                            actual_speed = max(1.1, min(10.0, speed_multiplier))

                            clip = clip.fx(mp.vfx.speedx, actual_speed)

                            # Dodaj overlay tylko je≈õli tworzymy wideo
                            if create_video:
                                overlay_text = f"x{actual_speed:.1f}" if actual_speed != int(
                                    actual_speed) else f"x{int(actual_speed)}"
                                overlay = self.create_speed_overlay(overlay_text, clip.duration, (video.w, video.h))

                                if overlay:
                                    clip = mp.CompositeVideoClip([clip, overlay])

                            timeline_data.append({
                                'start': start,
                                'end': end,
                                'duration': clip.duration,
                                'original_duration': duration,
                                'speed': actual_speed,
                                'type': 'silence'
                            })
                            total_output_duration += clip.duration
                        else:
                            # Kr√≥tka cisza - zostaw normalnƒÖ
                            timeline_data.append({
                                'start': start,
                                'end': end,
                                'duration': duration,
                                'speed': 1.0,
                                'type': 'short_silence'
                            })
                            total_output_duration += duration

                    processed_clips.append(clip)

                except Exception as e:
                    self.logger.error(f"B≈ÇƒÖd przetwarzania segmentu {start}-{end}: {e}")
                    continue

            if not processed_clips:
                raise ValueError("Nie uda≈Ço siƒô przetworzyƒá ≈ºadnego segmentu")

            # Tw√≥rz wideo tylko je≈õli wymagane
            output_path = None
            if create_video:
                self._update_progress("≈ÅƒÖczenie klip√≥w...")
                try:
                    final_video = mp.concatenate_videoclips(processed_clips, method="compose")

                    input_name = Path(input_path).stem
                    output_path = os.path.join(output_folder, f"{input_name}_processed.mp4")

                    self._update_progress("Zapisywanie wideo...")
                    final_video.write_videofile(
                        output_path,
                        codec='libx264',
                        audio_codec='aac',
                        temp_audiofile=os.path.join(output_folder, 'temp_audio.m4a'),
                        remove_temp=True,
                        verbose=False,
                        logger=None
                    )

                    final_video.close()

                except Exception as e:
                    self.logger.error(f"B≈ÇƒÖd tworzenia wideo: {e}")
                    output_path = None

            # Buduj wynik
            result = {
                'input_file': input_path,
                'input_name': Path(input_path).stem,
                'timeline_data': timeline_data,
                'original_duration': video.duration,
                'output_duration': total_output_duration,
                'segments_count': len(segments)
            }

            if output_path:
                result['output_video'] = output_path

            return result

        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd przetwarzania {input_path}: {e}")
            return None

        finally:
            # CLEANUP - bardzo wa≈ºne!
            try:
                if video:
                    video.close()

                for clip in processed_clips:
                    if clip:
                        clip.close()

            except Exception as e:
                self.logger.warning(f"B≈ÇƒÖd podczas cleanup: {e}")

    def generate_edl(self, results: List[dict], output_path: str):
        """Generuje plik EDL - NAPRAWIONY."""
        self._update_progress("Generowanie EDL...")

        if not results:
            self.logger.error("Brak danych do generowania EDL")
            return

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("TITLE: Processed_Videos\n")
                f.write("FCM: NON-DROP FRAME\n\n")

                edit_number = 1
                timeline_pos = 0.0

                for result_idx, result in enumerate(results):
                    if not result or 'timeline_data' not in result:
                        continue

                    source_name = result.get('input_name', f'VIDEO_{result_idx + 1}')
                    reel_name = f"AX{result_idx + 1:03d}"

                    for segment in result['timeline_data']:
                        try:
                            source_start = float(segment.get('start', 0))
                            original_duration = float(segment.get('original_duration', segment.get('duration', 1)))
                            source_end = source_start + original_duration
                            segment_duration = float(segment.get('duration', original_duration))

                            timeline_start = timeline_pos
                            timeline_end = timeline_pos + segment_duration

                            # Sprawd≈∫ poprawno≈õƒá czas√≥w
                            if source_end <= source_start or timeline_end <= timeline_start:
                                continue

                            # Timecode z obs≈ÇugƒÖ b≈Çƒôd√≥w
                            source_in_tc = self._seconds_to_timecode(source_start)
                            source_out_tc = self._seconds_to_timecode(source_end)
                            timeline_in_tc = self._seconds_to_timecode(timeline_start)
                            timeline_out_tc = self._seconds_to_timecode(timeline_end)

                            # Linia EDL
                            f.write(f"{edit_number:03d}  {reel_name:<8} V     C        ")
                            f.write(f"{source_in_tc} {source_out_tc} {timeline_in_tc} {timeline_out_tc}\n")

                            # Metadane
                            f.write(f"* FROM CLIP NAME: {source_name}\n")
                            f.write(f"* SEGMENT TYPE: {segment.get('type', 'unknown')}\n")

                            speed = float(segment.get('speed', 1.0))
                            if abs(speed - 1.0) > 0.01:  # Je≈õli speed != 1.0
                                f.write(f"* SPEED: {speed:.2f}\n")
                                speed_percent = speed * 100
                                f.write(
                                    f"M2   {reel_name:<8}     050 {timeline_in_tc} {timeline_out_tc} {speed_percent:06.2f} {speed_percent:06.2f}\n")

                            f.write("\n")

                            edit_number += 1
                            timeline_pos = timeline_end

                        except (ValueError, TypeError, KeyError) as e:
                            self.logger.warning(f"B≈ÇƒÖd przetwarzania segmentu w EDL: {e}")
                            continue

                # Mapowanie plik√≥w ≈∫r√≥d≈Çowych
                f.write("* SOURCE FILE MAPPING:\n")
                for result_idx, result in enumerate(results):
                    if result and 'input_file' in result:
                        reel_name = f"AX{result_idx + 1:03d}"
                        source_name = os.path.basename(result['input_file'])
                        f.write(f"* {reel_name}: {source_name}\n")

            self._update_progress(f"EDL zapisany: {output_path}")

        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd generowania EDL: {e}")
            raise

    def _seconds_to_timecode(self, seconds: float, fps: int = 25) -> str:
        """Konwertuje sekundy na timecode - NAPRAWIONY."""
        try:
            seconds = max(0.0, float(seconds))

            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = int(seconds % 60)
            frames = int((seconds % 1) * fps)

            # Sprawd≈∫ granice
            hours = min(23, hours)
            minutes = min(59, minutes)
            secs = min(59, secs)
            frames = min(fps - 1, frames)

            return f"{hours:02d}:{minutes:02d}:{secs:02d}:{frames:02d}"

        except (ValueError, TypeError):
            return "00:00:00:00"


class VideoProcessorGUI:
    """GUI dla Video Processor - NAPRAWIONY."""

    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Video Speed Processor v2.0 - FIXED")
        self.root.geometry("850x750")
        self.root.minsize(700, 600)

        # Zmienne
        self.input_folder = tk.StringVar()
        self.output_folder = tk.StringVar(value="output")
        self.speed_multiplier = tk.DoubleVar(value=3.0)
        self.min_silence_duration = tk.DoubleVar(value=1.5)
        self.detection_method = tk.StringVar(value="webrtc" if WEBRTC_AVAILABLE else "energy")
        self.create_video = tk.BooleanVar(value=True)
        self.create_edl = tk.BooleanVar(value=True)

        # Queue dla log√≥w
        self.log_queue = queue.Queue()

        # Stan przetwarzania
        self.is_processing = False

        self.setup_ui()
        self.check_dependencies()
        self.update_logs()

    def setup_ui(self):
        """Tworzy interfejs u≈ºytkownika - ULEPSZONY."""
        # Style
        style = ttk.Style()
        style.theme_use('clam')

        # Dodaj niestandardowe style
        style.configure('Title.TLabel', font=('Arial', 16, 'bold'))
        style.configure('Success.TLabel', foreground='green')
        style.configure('Warning.TLabel', foreground='orange')
        style.configure('Error.TLabel', foreground='red')

        # Main frame z scrollbar
        canvas = tk.Canvas(self.root)
        scrollbar = ttk.Scrollbar(self.root, orient="vertical", command=canvas.yview)
        scrollable_frame = ttk.Frame(canvas)

        scrollable_frame.bind(
            "<Configure>",
            lambda e: canvas.configure(scrollregion=canvas.bbox("all"))
        )

        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)

        main_frame = ttk.Frame(scrollable_frame, padding="15")
        main_frame.pack(fill=tk.BOTH, expand=True)

        # Configure grid
        main_frame.columnconfigure(1, weight=1)

        row = 0

        # Nag≈Ç√≥wek z wersjƒÖ
        header_frame = ttk.Frame(main_frame)
        header_frame.grid(row=row, column=0, columnspan=3, pady=(0, 20), sticky=(tk.W, tk.E))

        ttk.Label(header_frame, text="Video Speed Processor", style='Title.TLabel').pack(side=tk.LEFT)
        ttk.Label(header_frame, text="v2.0 - FIXED", foreground='blue', font=('Arial', 10)).pack(side=tk.RIGHT)
        row += 1

        # Status systemu
        self.system_status_frame = ttk.LabelFrame(main_frame, text="Status systemu", padding="10")
        self.system_status_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 15))
        row += 1

        # Folder wej≈õciowy
        ttk.Label(main_frame, text="Folder z plikami MP4:", font=('Arial', 10, 'bold')).grid(row=row, column=0,
                                                                                             sticky=tk.W, pady=8)
        self.input_entry = ttk.Entry(main_frame, textvariable=self.input_folder, width=55)
        self.input_entry.grid(row=row, column=1, sticky=(tk.W, tk.E), pady=8, padx=(10, 5))
        ttk.Button(main_frame, text="üìÅ PrzeglƒÖdaj", command=self.browse_input_folder).grid(row=row, column=2, pady=8)
        row += 1

        # PodglƒÖd znalezionych plik√≥w
        self.files_info_label = ttk.Label(main_frame, text="", foreground='gray')
        self.files_info_label.grid(row=row, column=1, sticky=tk.W, padx=(10, 0))
        row += 1

        # Folder wyj≈õciowy
        ttk.Label(main_frame, text="Folder wyj≈õciowy:", font=('Arial', 10, 'bold')).grid(row=row, column=0, sticky=tk.W,
                                                                                         pady=8)
        ttk.Entry(main_frame, textvariable=self.output_folder, width=55).grid(row=row, column=1, sticky=(tk.W, tk.E),
                                                                              pady=8, padx=(10, 5))
        ttk.Button(main_frame, text="üìÅ PrzeglƒÖdaj", command=self.browse_output_folder).grid(row=row, column=2, pady=8)
        row += 1

        # Separator
        ttk.Separator(main_frame, orient='horizontal').grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E),
                                                            pady=25)
        row += 1

        # Ustawienia zaawansowane
        settings_frame = ttk.LabelFrame(main_frame, text="‚öôÔ∏è Ustawienia przetwarzania", padding="12")
        settings_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=12)
        settings_frame.columnconfigure(1, weight=1)
        row += 1

        settings_row = 0

        # Mno≈ºnik prƒôdko≈õci z lepszƒÖ kontrolƒÖ
        ttk.Label(settings_frame, text="Przyspieszenie ciszy:", font=('Arial', 9, 'bold')).grid(row=settings_row,
                                                                                                column=0, sticky=tk.W,
                                                                                                pady=8)
        speed_frame = ttk.Frame(settings_frame)
        speed_frame.grid(row=settings_row, column=1, sticky=(tk.W, tk.E), pady=8, padx=(15, 0))
        speed_frame.columnconfigure(0, weight=1)

        self.speed_scale = ttk.Scale(speed_frame, from_=1.5, to=5.0, variable=self.speed_multiplier,
                                     orient=tk.HORIZONTAL)
        self.speed_scale.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 10))

        self.speed_label = ttk.Label(speed_frame, text="3.0x", width=8, background='lightblue', relief='solid')
        self.speed_label.grid(row=0, column=1)
        settings_row += 1

        # Minimalna cisza
        ttk.Label(settings_frame, text="Min. d≈Çugo≈õƒá ciszy (s):", font=('Arial', 9, 'bold')).grid(row=settings_row,
                                                                                                  column=0, sticky=tk.W,
                                                                                                  pady=8)
        silence_frame = ttk.Frame(settings_frame)
        silence_frame.grid(row=settings_row, column=1, sticky=(tk.W, tk.E), pady=8, padx=(15, 0))
        silence_frame.columnconfigure(0, weight=1)

        self.silence_scale = ttk.Scale(silence_frame, from_=0.5, to=4.0, variable=self.min_silence_duration,
                                       orient=tk.HORIZONTAL)
        self.silence_scale.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 10))

        self.silence_label = ttk.Label(silence_frame, text="1.5s", width=8, background='lightgreen', relief='solid')
        self.silence_label.grid(row=0, column=1)
        settings_row += 1

        # Metoda detekcji z opisami
        ttk.Label(settings_frame, text="Metoda detekcji mowy:", font=('Arial', 9, 'bold')).grid(row=settings_row,
                                                                                                column=0, sticky=tk.W,
                                                                                                pady=8)
        detection_frame = ttk.Frame(settings_frame)
        detection_frame.grid(row=settings_row, column=1, sticky=(tk.W, tk.E), pady=8, padx=(15, 0))

        methods = []
        if WHISPER_AVAILABLE:
            methods.append(("ü§ñ Whisper AI (najdok≈Çadniejszy)", "whisper"))
        if WEBRTC_AVAILABLE:
            methods.append(("‚ö° WebRTC VAD (szybki)", "webrtc"))
        methods.append(("üìä Analiza energii (podstawowy)", "energy"))

        for text, value in methods:
            ttk.Radiobutton(detection_frame, text=text, variable=self.detection_method, value=value).pack(anchor=tk.W,
                                                                                                          pady=2)
        settings_row += 1

        # Opcje generowania
        options_frame = ttk.LabelFrame(main_frame, text="üì§ Opcje wyj≈õciowe", padding="12")
        options_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=12)
        row += 1

        ttk.Checkbutton(options_frame, text="üé• Generuj przetworzone pliki MP4 (z overlayami prƒôdko≈õci)",
                        variable=self.create_video).pack(anchor=tk.W, pady=4)
        ttk.Checkbutton(options_frame, text="üé¨ Generuj timeline EDL dla DaVinci Resolve",
                        variable=self.create_edl).pack(anchor=tk.W, pady=4)

        # Przyciski g≈Ç√≥wne
        buttons_frame = ttk.Frame(main_frame)
        buttons_frame.grid(row=row, column=0, columnspan=3, pady=25)
        row += 1

        self.process_button = ttk.Button(buttons_frame, text="üöÄ Rozpocznij przetwarzanie",
                                         command=self.start_processing, width=25)
        self.process_button.pack(side=tk.LEFT, padx=(0, 15))

        self.stop_button = ttk.Button(buttons_frame, text="‚èπÔ∏è Zatrzymaj",
                                      command=self.stop_processing, state='disabled', width=15)
        self.stop_button.pack(side=tk.LEFT, padx=(0, 15))

        ttk.Button(buttons_frame, text="‚ùì Pomoc", command=self.show_help, width=10).pack(side=tk.LEFT, padx=(0, 15))
        ttk.Button(buttons_frame, text="üìÅ Otw√≥rz wyniki", command=self.open_output_folder, width=15).pack(side=tk.LEFT)

        # Progress z lepszym wy≈õwietlaniem
        progress_frame = ttk.LabelFrame(main_frame, text="üìä Postƒôp przetwarzania", padding="10")
        progress_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=12)
        progress_frame.columnconfigure(0, weight=1)
        row += 1

        self.progress_var = tk.StringVar(value="Gotowy do pracy ‚úÖ")
        self.progress_label = ttk.Label(progress_frame, textvariable=self.progress_var, font=('Arial', 10))
        self.progress_label.grid(row=0, column=0, sticky=tk.W, pady=(0, 8))

        self.progress_bar = ttk.Progressbar(progress_frame, mode='determinate', length=400)
        self.progress_bar.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 8))

        # Informacje o czasie
        self.time_info = ttk.Label(progress_frame, text="", foreground='gray', font=('Arial', 9))
        self.time_info.grid(row=2, column=0, sticky=tk.W)

        # Logi z lepszym formatowaniem
        log_frame = ttk.LabelFrame(main_frame, text="üìã Logi systemu", padding="8")
        log_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=12)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        main_frame.rowconfigure(row, weight=1)

        # Log text z kontrolkami
        log_controls = ttk.Frame(log_frame)
        log_controls.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 5))

        ttk.Button(log_controls, text="üóëÔ∏è Wyczy≈õƒá logi", command=self.clear_logs, width=15).pack(side=tk.LEFT)
        ttk.Button(log_controls, text="üíæ Zapisz logi", command=self.save_logs, width=15).pack(side=tk.LEFT,
                                                                                              padx=(10, 0))

        self.log_text = scrolledtext.ScrolledText(log_frame, height=12, state=tk.DISABLED,
                                                  font=('Consolas', 9), wrap=tk.WORD)
        self.log_text.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # Konfiguruj tags dla kolor√≥w
        self.log_text.tag_config("SUCCESS", foreground="green")
        self.log_text.tag_config("WARNING", foreground="orange")
        self.log_text.tag_config("ERROR", foreground="red")
        self.log_text.tag_config("INFO", foreground="blue")

        # Pack canvas i scrollbar
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        # Bindowanie zdarze≈Ñ
        self.speed_multiplier.trace('w', self.update_speed_label)
        self.min_silence_duration.trace('w', self.update_silence_label)
        self.input_folder.trace('w', self.update_files_info)

        # Bind mouse wheel dla canvas
        def _on_mousewheel(event):
            canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")

        canvas.bind_all("<MouseWheel>", _on_mousewheel)

    def update_speed_label(self, *args):
        """Aktualizuje label prƒôdko≈õci."""
        value = round(self.speed_multiplier.get(), 1)
        self.speed_label.config(text=f"{value}x")

    def update_silence_label(self, *args):
        """Aktualizuje label ciszy."""
        value = round(self.min_silence_duration.get(), 1)
        self.silence_label.config(text=f"{value}s")

    def update_files_info(self, *args):
        """Aktualizuje informacje o znalezionych plikach."""
        folder = self.input_folder.get()
        if folder and os.path.exists(folder):
            try:
                mp4_files = list(Path(folder).glob("*.mp4"))
                if mp4_files:
                    total_size = sum(f.stat().st_size for f in mp4_files) / (1024 * 1024)  # MB
                    self.files_info_label.config(
                        text=f"‚úÖ Znaleziono {len(mp4_files)} plik√≥w MP4 ({total_size:.1f} MB)",
                        foreground='green'
                    )
                else:
                    self.files_info_label.config(text="‚ö†Ô∏è Brak plik√≥w MP4 w folderze", foreground='orange')
            except Exception as e:
                self.files_info_label.config(text=f"‚ùå B≈ÇƒÖd odczytu folderu: {e}", foreground='red')
        else:
            self.files_info_label.config(text="", foreground='gray')

    def browse_input_folder(self):
        """Wyb√≥r folderu wej≈õciowego."""
        folder = filedialog.askdirectory(title="Wybierz folder z plikami MP4")
        if folder:
            self.input_folder.set(folder)

    def browse_output_folder(self):
        """Wyb√≥r folderu wyj≈õciowego."""
        folder = filedialog.askdirectory(title="Wybierz folder wyj≈õciowy")
        if folder:
            self.output_folder.set(folder)

    def check_dependencies(self):
        """Sprawdza dostƒôpno≈õƒá bibliotek - ULEPSZONY."""
        status_items = []

        # Sprawd≈∫ MoviePy/FFmpeg
        try:
            test_clip = mp.ColorClip(size=(100, 100), color=(0, 0, 0), duration=0.1)
            test_clip.close()
            status_items.append(("‚úÖ MoviePy/FFmpeg", "green"))
        except Exception as e:
            status_items.append(("‚ùå MoviePy/FFmpeg", "red"))
            self.add_log(f"B≈ÅƒÑD MoviePy: {e}", "ERROR")

        # Sprawd≈∫ WebRTC
        if WEBRTC_AVAILABLE:
            status_items.append(("‚úÖ WebRTC VAD", "green"))
        else:
            status_items.append(("‚ö†Ô∏è WebRTC VAD", "orange"))

        # Sprawd≈∫ Whisper
        if WHISPER_AVAILABLE:
            status_items.append(("‚úÖ Whisper AI", "green"))
        else:
            status_items.append(("‚ö†Ô∏è Whisper AI", "orange"))

        # Sprawd≈∫ ImageMagick
        try:
            test_clip = mp.TextClip("test", fontsize=20, color='white').set_duration(0.1)
            test_clip.close()
            status_items.append(("‚úÖ ImageMagick (overlaye)", "green"))
        except Exception:
            status_items.append(("‚ö†Ô∏è ImageMagick (kolorowe overlaye)", "orange"))

        # Wy≈õwietl status
        for widget in self.system_status_frame.winfo_children():
            widget.destroy()

        for i, (text, color) in enumerate(status_items):
            row = i // 2
            col = i % 2
            ttk.Label(self.system_status_frame, text=text, foreground=color).grid(
                row=row, column=col, sticky=tk.W, padx=(0, 20), pady=2
            )

    def add_log(self, message, tag="INFO"):
        """Dodaje wiadomo≈õƒá do log√≥w z kolorami."""
        timestamp = tk.datetime.datetime.now().strftime("%H:%M:%S")
        formatted_message = f"[{timestamp}] {message}\n"

        self.log_text.config(state=tk.NORMAL)
        self.log_text.insert(tk.END, formatted_message, tag)
        self.log_text.see(tk.END)
        self.log_text.config(state=tk.DISABLED)

    def clear_logs(self):
        """Czy≈õci logi."""
        self.log_text.config(state=tk.NORMAL)
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state=tk.DISABLED)

    def save_logs(self):
        """Zapisuje logi do pliku."""
        try:
            filename = filedialog.asksaveasfilename(
                defaultextension=".txt",
                filetypes=[("Pliki tekstowe", "*.txt"), ("Wszystkie pliki", "*.*")],
                title="Zapisz logi"
            )
            if filename:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(self.log_text.get(1.0, tk.END))
                self.add_log(f"Logi zapisane: {filename}", "SUCCESS")
        except Exception as e:
            self.add_log(f"B≈ÇƒÖd zapisu log√≥w: {e}", "ERROR")

    def update_logs(self):
        """Aktualizuje logi z queue."""
        try:
            while True:
                message = self.log_queue.get_nowait()
                # Okre≈õl tag na podstawie tre≈õci
                if "ERROR" in message or "B≈ÇƒÖd" in message:
                    tag = "ERROR"
                elif "WARNING" in message or "‚ö†Ô∏è" in message:
                    tag = "WARNING"
                elif "‚úÖ" in message or "Uko≈Ñczono" in message:
                    tag = "SUCCESS"
                else:
                    tag = "INFO"
                self.add_log(message, tag)
        except queue.Empty:
            pass

        # Sprawd≈∫ ponownie za 100ms
        self.root.after(100, self.update_logs)

    def update_progress(self, message, progress=None):
        """Callback do aktualizacji progressu - ULEPSZONY."""
        self.progress_var.set(message)

        if progress is not None:
            self.progress_bar.config(mode='determinate')
            self.progress_bar['value'] = min(100, max(0, progress))

            # Oszacuj pozosta≈Çy czas
            if hasattr(self, 'start_time') and progress > 0:
                elapsed = time.time() - self.start_time
                if progress > 5:  # Dopiero po 5% pokazuj oszacowanie
                    total_estimated = elapsed * 100 / progress
                    remaining = total_estimated - elapsed
                    self.time_info.config(text=f"Pozosta≈Ço: ~{remaining / 60:.1f} min")
        else:
            self.progress_bar.config(mode='indeterminate')
            if not self.progress_bar.instate(['active']):
                self.progress_bar.start()

    def start_processing(self):
        """Rozpoczyna przetwarzanie w osobnym wƒÖtku - ULEPSZONY."""
        # Walidacja
        if not self.input_folder.get():
            messagebox.showerror("B≈ÇƒÖd", "Wybierz folder z plikami MP4!")
            return

        if not os.path.exists(self.input_folder.get()):
            messagebox.showerror("B≈ÇƒÖd", "Folder wej≈õciowy nie istnieje!")
            return

        # Znajd≈∫ pliki MP4
        try:
            mp4_files = list(Path(self.input_folder.get()).glob("*.mp4"))
            if not mp4_files:
                messagebox.showerror("B≈ÇƒÖd", "Nie znaleziono plik√≥w MP4 w wybranym folderze!")
                return
        except Exception as e:
            messagebox.showerror("B≈ÇƒÖd", f"Nie mo≈ºna odczytaƒá folderu: {e}")
            return

        # Sprawd≈∫ czy co najmniej jedna opcja jest w≈ÇƒÖczona
        if not self.create_video.get() and not self.create_edl.get():
            messagebox.showwarning("Uwaga", "Wybierz co najmniej jednƒÖ opcjƒô wyj≈õciowƒÖ!")
            return

        # Potwierd≈∫ rozpoczƒôcie
        if len(mp4_files) > 5:
            if not messagebox.askyesno("Potwierdzenie",
                                       f"Znaleziono {len(mp4_files)} plik√≥w do przetworzenia.\n"
                                       f"To mo≈ºe zajƒÖƒá du≈ºo czasu. Kontynuowaƒá?"):
                return

        # Przygotuj UI
        self.is_processing = True
        self.process_button.config(state='disabled')
        self.stop_button.config(state='normal')
        self.progress_bar.config(mode='indeterminate')
        self.progress_bar.start()

        import time
        self.start_time = time.time()

        self.add_log(f"üöÄ Rozpoczynanie przetwarzania {len(mp4_files)} plik√≥w...", "INFO")

        # Uruchom w wƒÖtku
        self.processing_thread = threading.Thread(target=self.process_videos, args=(mp4_files,), daemon=True)
        self.processing_thread.start()

    def stop_processing(self):
        """Zatrzymuje przetwarzanie."""
        self.is_processing = False
        self.add_log("‚èπÔ∏è Zatrzymywanie przetwarzania...", "WARNING")

    def process_videos(self, mp4_files):
        """Przetwarza pliki wideo - NAPRAWIONY."""
        try:
            # Przygotuj foldery
            output_folder = Path(self.output_folder.get())
            output_folder.mkdir(parents=True, exist_ok=True)

            # Utw√≥rz procesor
            processor = VideoProcessor(
                progress_callback=self.update_progress,
                log_callback=self.add_log
            )

            results = []
            successful = 0
            failed = 0

            for i, mp4_file in enumerate(mp4_files):
                if not self.is_processing:
                    self.root.after(0, lambda: self.add_log("‚ùå Przetwarzanie anulowane przez u≈ºytkownika", "WARNING"))
                    break

                file_progress = (i / len(mp4_files)) * 100
                self.root.after(0, lambda msg=f"üìπ Przetwarzanie: {mp4_file.name} ({i + 1}/{len(mp4_files)})",
                                          prog=file_progress:
                self.update_progress(msg, prog))

                try:
                    result = processor.process_video(
                        str(mp4_file),
                        str(output_folder),
                        speed_multiplier=self.speed_multiplier.get(),
                        min_silence_duration=self.min_silence_duration.get(),
                        detection_method=self.detection_method.get(),
                        create_video=self.create_video.get()
                    )

                    if result:
                        results.append(result)
                        successful += 1

                        # Skopiuj oryginalny plik do output (dla EDL)
                        if self.create_edl.get():
                            dest_path = output_folder / mp4_file.name
                            if not dest_path.exists():
                                shutil.copy2(mp4_file, dest_path)

                        self.root.after(0, lambda name=mp4_file.name:
                        self.add_log(f"‚úÖ Uko≈Ñczono: {name}", "SUCCESS"))
                    else:
                        failed += 1
                        self.root.after(0, lambda name=mp4_file.name:
                        self.add_log(f"‚ùå Niepowodzenie: {name}", "ERROR"))

                except Exception as e:
                    failed += 1
                    self.root.after(0, lambda name=mp4_file.name, err=str(e):
                    self.add_log(f"‚ùå B≈ÇƒÖd {name}: {err}", "ERROR"))

            # Zapisz dane jako JSON
            if results:
                try:
                    json_path = output_folder / "timeline_data.json"
                    with open(json_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, indent=2, ensure_ascii=False, default=str)

                    self.root.after(0, lambda: self.add_log("üíæ Dane timeline zapisane do JSON", "SUCCESS"))
                except Exception as e:
                    self.root.after(0, lambda err=str(e): self.add_log(f"‚ö†Ô∏è B≈ÇƒÖd zapisu JSON: {err}", "WARNING"))

                # Generuj EDL je≈õli wymagane
                if self.create_edl.get():
                    try:
                        edl_path = output_folder / "timeline.edl"
                        processor.generate_edl(results, str(edl_path))
                        self.root.after(0, lambda: self.add_log("üé¨ Timeline EDL wygenerowany", "SUCCESS"))
                    except Exception as e:
                        self.root.after(0, lambda err=str(e): self.add_log(f"‚ùå B≈ÇƒÖd generowania EDL: {err}", "ERROR"))

                self.root.after(0, self.processing_complete, successful, failed, str(output_folder))
            else:
                self.root.after(0, lambda: self.add_log("‚ùå Nie uda≈Ço siƒô przetworzyƒá ≈ºadnego pliku", "ERROR"))
                self.root.after(0, lambda: self.update_progress("‚ùå Przetwarzanie nieudane"))

        except Exception as e:
            self.root.after(0, lambda err=str(e): self.add_log(f"‚ùå Krytyczny b≈ÇƒÖd: {err}", "ERROR"))
            self.root.after(0, lambda err=str(e): self.update_progress(f"‚ùå Krytyczny b≈ÇƒÖd: {err}"))
        finally:
            self.root.after(0, self.processing_finished)

    def processing_complete(self, successful, failed, output_path):
        """Wywo≈Çane po zako≈Ñczeniu przetwarzania - ULEPSZONY."""
        total_time = time.time() - self.start_time if hasattr(self, 'start_time') else 0

        status = f"‚úÖ Przetwarzanie uko≈Ñczone!"
        self.update_progress(status, 100)

        # Szczeg√≥≈Çowy raport
        self.add_log(f"üìä RAPORT KO≈ÉCOWY:", "SUCCESS")
        self.add_log(f"   ‚Ä¢ Przetworzonych: {successful} plik√≥w", "SUCCESS")
        if failed > 0:
            self.add_log(f"   ‚Ä¢ Niepowodze≈Ñ: {failed} plik√≥w", "WARNING")
        self.add_log(f"   ‚Ä¢ Ca≈Çkowity czas: {total_time / 60:.1f} min", "INFO")
        self.add_log(f"   ‚Ä¢ Wyniki w: {output_path}", "INFO")

        # Informacje o EDL
        if self.create_edl.get():
            edl_path = os.path.join(output_path, "timeline.edl")
            if os.path.exists(edl_path):
                self.add_log("üé¨ Timeline EDL gotowy do importu w DaVinci Resolve", "SUCCESS")
                self.add_log("   IMPORT: File ‚Üí Import ‚Üí Timeline ‚Üí Pre-Conform", "INFO")
                self.add_log("   Wybierz plik: timeline.edl", "INFO")

        # Informacje o wygenerowanych plikach
        if self.create_video.get():
            processed_files = len([f for f in os.listdir(output_path) if f.endswith('_processed.mp4')])
            if processed_files > 0:
                self.add_log(f"üé• Wygenerowano {processed_files} przetworzonych plik√≥w MP4", "SUCCESS")

        # Aktualizuj informacje o czasie
        self.time_info.config(text=f"Uko≈Ñczono w {total_time / 60:.1f} min")

        # Poka≈º messagebox z podsumowaniem
        success_msg = f"Pomy≈õlnie przetworzono {successful} z {successful + failed} plik√≥w!"
        if failed > 0:
            success_msg += f"\n\nNiepowodzenia: {failed} plik√≥w (sprawd≈∫ logi)"

        success_msg += f"\n\nCzas przetwarzania: {total_time / 60:.1f} min"
        success_msg += f"\nWyniki zapisane w:\n{output_path}"

        if self.create_edl.get():
            success_msg += "\n\nüé¨ Timeline EDL gotowy do importu!"

        messagebox.showinfo("Przetwarzanie uko≈Ñczone", success_msg)

    def processing_finished(self):
        """Przywraca GUI po zako≈Ñczeniu - ULEPSZONY."""
        self.is_processing = False
        self.process_button.config(state='normal', text="üöÄ Rozpocznij przetwarzanie")
        self.stop_button.config(state='disabled')

        # Zatrzymaj progress bar
        self.progress_bar.stop()
        self.progress_bar.config(mode='determinate', value=0)

        # Reset statusu
        if not hasattr(self, 'start_time'):
            self.progress_var.set("Gotowy do pracy ‚úÖ")
            self.time_info.config(text="")

    def open_output_folder(self):
        """Otwiera folder wyj≈õciowy - ULEPSZONY."""
        output_path = self.output_folder.get()

        if not output_path:
            output_path = "output"

        # Utw√≥rz folder je≈õli nie istnieje
        os.makedirs(output_path, exist_ok=True)

        try:
            if sys.platform == "win32":
                os.startfile(output_path)
            elif sys.platform == "darwin":
                os.system(f"open '{output_path}'")
            else:
                os.system(f"xdg-open '{output_path}'")

            self.add_log(f"üìÅ Otwarto folder: {os.path.abspath(output_path)}", "INFO")

        except Exception as e:
            self.add_log(f"‚ùå Nie mo≈ºna otworzyƒá folderu: {e}", "ERROR")
            messagebox.showwarning("Uwaga", f"Nie mo≈ºna otworzyƒá folderu:\n{os.path.abspath(output_path)}")

    def show_help(self):
        """Wy≈õwietla okno pomocy - ULEPSZONY."""
        help_window = tk.Toplevel(self.root)
        help_window.title("Pomoc - Video Speed Processor v2.0")
        help_window.geometry("700x600")
        help_window.transient(self.root)
        help_window.grab_set()
        help_window.resizable(True, True)

        # Ikona (je≈õli dostƒôpna)
        try:
            help_window.iconbitmap(self.root.iconbitmap())
        except:
            pass

        # Main frame z scrollbar
        canvas = tk.Canvas(help_window)
        scrollbar = ttk.Scrollbar(help_window, orient="vertical", command=canvas.yview)
        scrollable_frame = ttk.Frame(canvas)

        scrollable_frame.bind(
            "<Configure>",
            lambda e: canvas.configure(scrollregion=canvas.bbox("all"))
        )

        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)

        # Content frame
        content_frame = ttk.Frame(scrollable_frame, padding="20")
        content_frame.pack(fill=tk.BOTH, expand=True)

        # Tekst pomocy - ROZSZERZONY
        help_text = """üé¨ Video Speed Processor v2.0 - FIXED - Pomoc

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üöÄ JAK U≈ªYWAƒÜ:

1. üìÅ WYB√ìR PLIK√ìW
   ‚Ä¢ Wybierz folder zawierajƒÖcy pliki MP4
   ‚Ä¢ Program automatycznie znajdzie wszystkie pliki .mp4
   ‚Ä¢ Sprawd≈∫ czy pokazuje siƒô prawid≈Çowa liczba plik√≥w

2. ‚öôÔ∏è KONFIGURACJA
   ‚Ä¢ Folder wyj≈õciowy: gdzie zapisaƒá wyniki (domy≈õlnie 'output')
   ‚Ä¢ Przyspieszenie ciszy: 1.5x - 5x (zalecane: 3x)
   ‚Ä¢ Min. d≈Çugo≈õƒá ciszy: 0.5s - 4s (zalecane: 1.5s)
   ‚Ä¢ Metoda detekcji: WebRTC/Whisper/Energia

3. üì§ OPCJE WYJ≈öCIOWE
   ‚úÖ Przetworzone wideo MP4 - z overlayami prƒôdko≈õci
   ‚úÖ Timeline EDL - dla DaVinci Resolve

4. üé¨ PRZETWARZANIE
   ‚Ä¢ Kliknij "Rozpocznij przetwarzanie"
   ‚Ä¢ Obserwuj postƒôp w logach
   ‚Ä¢ Poczekaj na zako≈Ñczenie

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîß CO ROBI PROGRAM:

‚Ä¢ üé§ DETEKCJA MOWY: Automatycznie rozpoznaje fragmenty z mowƒÖ
‚Ä¢ ‚ö° PRZYSPIESZANIE: Przyspiesza tylko fragmenty ciszy
‚Ä¢ üì∫ OVERLAY: Dodaje widoczny wska≈∫nik "x3" podczas przyspieszenia
‚Ä¢ üé¨ EDL EXPORT: Tworzy timeline gotowy do DaVinci Resolve
‚Ä¢ üìä STATYSTYKI: Pokazuje oszczƒôdno≈õƒá czasu

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ METODY DETEKCJI:

ü§ñ WHISPER AI (najdok≈Çadniejszy)
   ‚Ä¢ Rozpoznaje mowƒô w r√≥≈ºnych jƒôzykach
   ‚Ä¢ Najlepsza jako≈õƒá detekcji
   ‚Ä¢ Wymaga wiƒôcej czasu i mocy CPU
   ‚Ä¢ Idealny dla: podcast√≥w, wywiad√≥w, prezentacji

‚ö° WEBRTC VAD (szybki)
   ‚Ä¢ Bardzo szybka detekcja w czasie rzeczywistym
   ‚Ä¢ Niskie u≈ºycie zasob√≥w
   ‚Ä¢ Dobry dla czystego audio
   ‚Ä¢ Idealny dla: gamingu, screencast√≥w

üìä ANALIZA ENERGII (podstawowy)
   ‚Ä¢ Zawsze dostƒôpny (fallback)
   ‚Ä¢ Bazuje na g≈Ço≈õno≈õci d≈∫wiƒôku
   ‚Ä¢ Najmniej precyzyjny
   ‚Ä¢ U≈ºywany gdy inne metody niedostƒôpne

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üé¨ IMPORT DO DAVINCI RESOLVE:

1. üìÇ PRZYGOTOWANIE
   ‚Ä¢ Upewnij siƒô ≈ºe folder 'output' zawiera:
     - timeline.edl (g≈Ç√≥wny plik)
     - oryginalne pliki MP4
     - (opcjonalnie) przetworzone pliki MP4

2. üì• IMPORT TIMELINE
   ‚Ä¢ File ‚Üí Import ‚Üí Timeline ‚Üí Pre-Conform
   ‚Ä¢ Wybierz plik 'timeline.edl'
   ‚Ä¢ DaVinci automatycznie zaimportuje timeline

3. ‚úÖ WERYFIKACJA
   ‚Ä¢ Timeline zawiera wszystkie klipy z oryginalnymi nazwami
   ‚Ä¢ Efekty prƒôdko≈õci sƒÖ ju≈º zastosowane
   ‚Ä¢ Sprawd≈∫ czy d≈Çugo≈õƒá timeline siƒô zgadza

4. üé® FINALIZACJA
   ‚Ä¢ Dodaj kolorystykƒô, napisy, efekty
   ‚Ä¢ Timeline jest gotowy do dalszej obr√≥bki

DLACZEGO EDL?
‚Ä¢ Natywne wsparcie w DaVinci Resolve
‚Ä¢ Precyzyjny timecode (ramka po ramce)
‚Ä¢ Zawiera informacje o efektach prƒôdko≈õci
‚Ä¢ Bezproblemowy import

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚öôÔ∏è USTAWIENIA DLA R√ì≈ªNYCH TRE≈öCI:

üéÆ GAMING Z KOMENTARZEM
   ‚Ä¢ Przyspieszenie: 2.5x - 3x
   ‚Ä¢ Min. cisza: 1.5s
   ‚Ä¢ Detekcja: WebRTC VAD
   ‚Ä¢ Cel: usuniƒôcie pauz w komentarzu

üìö TUTORIALE/PREZENTACJE
   ‚Ä¢ Przyspieszenie: 2x - 2.5x
   ‚Ä¢ Min. cisza: 2s
   ‚Ä¢ Detekcja: Whisper AI
   ‚Ä¢ Cel: usuniƒôcie d≈Çugich pauz

üéôÔ∏è PODCASTY/WYWIADY
   ‚Ä¢ Przyspieszenie: 1.5x - 2x
   ‚Ä¢ Min. cisza: 1s
   ‚Ä¢ Detekcja: Whisper AI
   ‚Ä¢ Cel: naturalne tempo rozmowy

üéÆ GAMEPLAY BEZ KOMENTARZA
   ‚Ä¢ Przyspieszenie: 4x - 5x
   ‚Ä¢ Min. cisza: 3s
   ‚Ä¢ Detekcja: WebRTC VAD
   ‚Ä¢ Cel: dynamiczne przej≈õcia

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üõ†Ô∏è ROZWIƒÑZYWANIE PROBLEM√ìW:

‚ùå "NIE ZNALEZIONO PLIK√ìW MP4"
   ‚Ä¢ Sprawd≈∫ czy w folderze sƒÖ pliki .mp4
   ‚Ä¢ Sprawd≈∫ wielko≈õƒá liter w rozszerzeniu
   ‚Ä¢ Upewnij siƒô ≈ºe masz uprawnienia do odczytu

‚ùå "B≈ÅƒÑD PRZETWARZANIA"
   ‚Ä¢ Sprawd≈∫ logi w programie (czerwone komunikaty)
   ‚Ä¢ Upewnij siƒô ≈ºe FFmpeg jest zainstalowany: ffmpeg -version
   ‚Ä¢ Sprawd≈∫ czy pliki MP4 nie sƒÖ uszkodzone
   ‚Ä¢ Sprawd≈∫ czy masz wystarczajƒÖco miejsca na dysku

‚ö†Ô∏è "BRAK OVERLAY√ìW TEKSTOWYCH"
   ‚Ä¢ Zainstaluj ImageMagick (instrukcje w README)
   ‚Ä¢ Program u≈ºyje kolorowych wska≈∫nik√≥w jako zamiennik
   ‚Ä¢ To nie wp≈Çywa na funkcjonalno≈õƒá EDL

‚ö†Ô∏è "TIMELINE MA NIEPRAWID≈ÅOWƒÑ D≈ÅUGO≈öƒÜ"
   ‚Ä¢ Problem naprawiony w tej wersji!
   ‚Ä¢ EDL zawiera precyzyjne informacje o czasach
   ‚Ä¢ Sprawd≈∫ czy oryginalne pliki sƒÖ w folderze output

‚ùå "IMPORT EDL FAILED TO LINK"
   ‚Ä¢ Skopiuj oryginalne pliki MP4 do folderu output
   ‚Ä¢ Sprawd≈∫ czy nazwy plik√≥w nie zawierajƒÖ polskich znak√≥w
   ‚Ä¢ U≈ºyj "Relink" w DaVinci je≈õli potrzeba

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä WYDAJNO≈öƒÜ I OPTYMALIZACJA:

‚è±Ô∏è ORIENTACYJNE CZASY:
   ‚Ä¢ 5-min wideo: 1-3 min (WebRTC) / 3-8 min (Whisper)
   ‚Ä¢ 30-min wideo: 5-15 min (WebRTC) / 15-45 min (Whisper)
   ‚Ä¢ 2h podcast: 20-60 min (WebRTC) / 60-180 min (Whisper)

üöÄ PRZYSPIESZ PRZETWARZANIE:
   ‚Ä¢ U≈ºywaj WebRTC VAD dla szybko≈õci
   ‚Ä¢ Zamknij inne programy podczas przetwarzania
   ‚Ä¢ U≈ºyj SSD zamiast HDD
   ‚Ä¢ Wiƒôcej RAM = szybsze przetwarzanie

üíæ ZARZƒÑDZANIE MIEJSCEM:
   ‚Ä¢ Program tworzy pliki tymczasowe
   ‚Ä¢ Po zako≈Ñczeniu automatycznie je usuwa
   ‚Ä¢ Potrzeba ~2x wiƒôcej miejsca ni≈º rozmiar wideo
   ‚Ä¢ Folder output mo≈ºe byƒá du≈ºy

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üÜò WSPARCIE TECHNICZNE:

üìù ZBIERANIE INFORMACJI:
   1. Wersja Python: python --version
   2. System operacyjny i wersja
   3. Logi z programu (Zapisz logi ‚Üí plik .txt)
   4. Czy FFmpeg dzia≈Ça: ffmpeg -version
   5. Rozmiar i czas trwania problematycznego pliku

üîç DIAGNOSTYKA:
   ‚Ä¢ Sprawd≈∫ plik video_speed_processor.log
   ‚Ä¢ W≈ÇƒÖcz szczeg√≥≈Çowe logi w programie
   ‚Ä¢ Przetestuj z pojedynczym, kr√≥tkim plikiem
   ‚Ä¢ Sprawd≈∫ timeline_data.json dla szczeg√≥≈Ç√≥w

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéâ PRZYK≈ÅADOWY WORKFLOW:

1. üìπ NAGRANIE (OBS, Bandicam, itp.)
2. üé¨ PRZETWARZANIE (ten program)
3. üì• IMPORT DO DAVINCI (EDL timeline)
4. üé® OBR√ìBKA (kolorystyka, efekty, napisy)
5. üì§ EXPORT (YouTube, social media)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Program stworzony z my≈õlƒÖ o content creatorach!
Oszczƒôd≈∫ czas na monta≈ºu - skup siƒô na tre≈õci! üöÄ

Wersja: 2.0 FIXED - wszystkie g≈Ç√≥wne b≈Çƒôdy naprawione"""

        # Text widget z lepszym formatowaniem
        text_widget = scrolledtext.ScrolledText(
            content_frame,
            wrap=tk.WORD,
            font=('Consolas', 10),
            padx=15,
            pady=15,
            relief='solid',
            borderwidth=1
        )
        text_widget.pack(fill=tk.BOTH, expand=True)
        text_widget.insert(tk.END, help_text)
        text_widget.config(state=tk.DISABLED)

        # Konfiguracja tag√≥w dla kolor√≥w
        text_widget.tag_config("title", font=('Arial', 12, 'bold'), foreground='blue')
        text_widget.tag_config("section", font=('Arial', 11, 'bold'), foreground='darkgreen')
        text_widget.tag_config("warning", foreground='orange')
        text_widget.tag_config("error", foreground='red')
        text_widget.tag_config("success", foreground='green')

        # Przycisk zamknij
        button_frame = ttk.Frame(help_window, padding="10")
        button_frame.pack(fill=tk.X)

        ttk.Button(button_frame, text="‚úÖ Zamknij",
                   command=help_window.destroy,
                   width=15).pack(side=tk.RIGHT)

        ttk.Button(button_frame, text="üìÅ Otw√≥rz folder wyj≈õciowy",
                   command=lambda: (help_window.destroy(), self.open_output_folder()),
                   width=25).pack(side=tk.RIGHT, padx=(0, 10))

        # Pack canvas i scrollbar
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        # Bind mouse wheel
        def _on_mousewheel(event):
            canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")

        canvas.bind_all("<MouseWheel>", _on_mousewheel)

        # Focus na okno
        help_window.focus_set()

    def run(self):
        """Uruchamia aplikacjƒô - ULEPSZONY."""
        try:
            # Ustaw ikonƒô okna (je≈õli dostƒôpna)
            try:
                # Mo≈ºna dodaƒá custom ikonƒô tutaj
                pass
            except:
                pass

            # Ustaw pozycjƒô okna na ≈õrodku ekranu
            self.root.update_idletasks()
            width = self.root.winfo_width()
            height = self.root.winfo_height()
            x = (self.root.winfo_screenwidth() // 2) - (width // 2)
            y = (self.root.winfo_screenheight() // 2) - (height // 2)
            self.root.geometry(f"{width}x{height}+{x}+{y}")

            # Poka≈º okno
            self.root.deiconify()

            # Komunikat powitalny
            self.add_log("üé¨ Video Speed Processor v2.0 - FIXED", "INFO")
            self.add_log("‚ïê" * 50, "INFO")
            self.add_log("Gotowy do przetwarzania plik√≥w MP4!", "SUCCESS")
            self.add_log("Wybierz folder z plikami i kliknij 'Rozpocznij przetwarzanie'", "INFO")
            self.add_log("Pomoc: kliknij przycisk '‚ùì Pomoc' dla szczeg√≥≈Çowych instrukcji", "INFO")

            # Uruchom g≈Ç√≥wnƒÖ pƒôtlƒô
            self.root.mainloop()

        except KeyboardInterrupt:
            self.add_log("Program przerwany przez u≈ºytkownika", "WARNING")
        except Exception as e:
            self.add_log(f"Krytyczny b≈ÇƒÖd aplikacji: {e}", "ERROR")
            messagebox.showerror("Krytyczny b≈ÇƒÖd", f"Aplikacja napotka≈Ça nieoczekiwany b≈ÇƒÖd:\n\n{e}")
        finally:
            # Cleanup
            try:
                if hasattr(self, 'root'):
                    self.root.quit()
            except:
                pass


def main():
    """G≈Ç√≥wna funkcja - ULEPSZONY."""
    print("üé¨ Video Speed Processor v2.0 - FIXED")
    print("‚ïê" * 50)

    # Sprawd≈∫ Python version
    import sys
    if sys.version_info < (3, 8):
        print("‚ùå B≈ÅƒÑD: Wymagany Python 3.8+")
        print(f"   Aktualna wersja: {sys.version}")
        input("Naci≈õnij Enter aby zamknƒÖƒá...")
        return

    # Sprawd≈∫ podstawowe zale≈ºno≈õci
    missing_deps = []

    try:
        import moviepy.editor as mp
        print("‚úÖ MoviePy - OK")
    except ImportError:
        missing_deps.append("moviepy")
        print("‚ùå MoviePy - BRAK")

    try:
        import librosa
        print("‚úÖ Librosa - OK")
    except ImportError:
        missing_deps.append("librosa")
        print("‚ùå Librosa - BRAK")

    try:
        import numpy as np
        print("‚úÖ NumPy - OK")
    except ImportError:
        missing_deps.append("numpy")
        print("‚ùå NumPy - BRAK")

    # Sprawd≈∫ opcjonalne zale≈ºno≈õci
    try:
        import webrtcvad
        print("‚úÖ WebRTC VAD - OK")
    except ImportError:
        print("‚ö†Ô∏è WebRTC VAD - BRAK (opcjonalne)")

    try:
        import whisper
        print("‚úÖ Whisper AI - OK")
    except ImportError:
        print("‚ö†Ô∏è Whisper AI - BRAK (opcjonalne)")

    # Sprawd≈∫ FFmpeg
    try:
        import subprocess
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("‚úÖ FFmpeg - OK")
        else:
            print("‚ö†Ô∏è FFmpeg - PROBLEM")
    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
        print("‚ùå FFmpeg - BRAK")
        missing_deps.append("ffmpeg")

    print("‚ïê" * 50)

    # Je≈õli brakuje krytycznych zale≈ºno≈õci
    if missing_deps:
        print(f"‚ùå B≈ÅƒÑD: Brak wymaganych bibliotek!")
        print(f"   Brakuje: {', '.join(missing_deps)}")
        print()
        print("üì• INSTALACJA:")
        if 'moviepy' in missing_deps or 'librosa' in missing_deps or 'numpy' in missing_deps:
            print("   pip install moviepy librosa numpy")
        if 'ffmpeg' in missing_deps:
            print("   Zainstaluj FFmpeg z https://ffmpeg.org/")
        print()

        # Poka≈º messagebox je≈õli GUI jest dostƒôpne
        try:
            import tkinter as tk
            from tkinter import messagebox
            root = tk.Tk()
            root.withdraw()
            messagebox.showerror(
                "Brak wymaganych bibliotek",
                f"Brakuje wymaganych bibliotek:\n{', '.join(missing_deps)}\n\n"
                f"Zainstaluj:\npip install moviepy librosa numpy\n\n"
                f"Oraz FFmpeg z https://ffmpeg.org/"
            )
            root.destroy()
        except:
            pass

        input("Naci≈õnij Enter aby zamknƒÖƒá...")
        return

    print("üöÄ Uruchamianie GUI...")

    # Uruchom GUI
    try:
        app = VideoProcessorGUI()
        app.run()
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd uruchomienia GUI: {e}")

        # Poka≈º messagebox z b≈Çƒôdem
        try:
            import tkinter as tk
            from tkinter import messagebox
            root = tk.Tk()
            root.withdraw()
            messagebox.showerror(
                "B≈ÇƒÖd uruchomienia",
                f"Nie mo≈ºna uruchomiƒá interfejsu graficznego:\n\n{e}"
            )
            root.destroy()
        except:
            pass

        input("Naci≈õnij Enter aby zamknƒÖƒá...")

    print("Dziƒôkujemy za u≈ºycie Video Speed Processor! üé¨")


if __name__ == "__main__":
    import time
    import datetime  # Dodajemy brakujƒÖcy import

    main()